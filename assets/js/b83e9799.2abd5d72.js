"use strict";(self.webpackChunkgg_interview_document=self.webpackChunkgg_interview_document||[]).push([[6799],{4755:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"project-docs/solution-requirements-document","title":"Software Requirements Specification (SRS)","description":"1. Introduction","source":"@site/docs/project-docs/solution-requirements-document.md","sourceDirName":"project-docs","slug":"/project-docs/solution-requirements-document","permalink":"/gg-interview-document-website/project-docs/solution-requirements-document","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Business Requirements Document (BRD)","permalink":"/gg-interview-document-website/project-docs/business-requirements-document"},"next":{"title":"Project Charter","permalink":"/gg-interview-document-website/project-docs/project-charter"}}');var t=i(4848),s=i(8453);const o={sidebar_position:2},l="Software Requirements Specification (SRS)",a={},c=[{value:"1. Introduction",id:"1-introduction",level:2},{value:"1.1 Purpose",id:"11-purpose",level:3},{value:"1.2 System Overview",id:"12-system-overview",level:3},{value:"1.3 Document Conventions",id:"13-document-conventions",level:3},{value:"1.4 Intended Audience",id:"14-intended-audience",level:3},{value:"2. System Architecture",id:"2-system-architecture",level:2},{value:"2.1 System Components",id:"21-system-components",level:3},{value:"2.2 Technology Stack",id:"22-technology-stack",level:3},{value:"Client-side",id:"client-side",level:4},{value:"Server-side",id:"server-side",level:4},{value:"3. Functional Requirements",id:"3-functional-requirements",level:2},{value:"3.1 Web Application",id:"31-web-application",level:3},{value:"FR-WA-01: User Interface",id:"fr-wa-01-user-interface",level:4},{value:"FR-WA-02: Main Interview Interface",id:"fr-wa-02-main-interview-interface",level:4},{value:"FR-WA-03: AI Service Integration",id:"fr-wa-03-ai-service-integration",level:4},{value:"FR-WA-04: Problem Service Integration",id:"fr-wa-04-problem-service-integration",level:4},{value:"FR-WA-05: Screen Sharing",id:"fr-wa-05-screen-sharing",level:4},{value:"FR-WA-06: Real-time Audio Communication",id:"fr-wa-06-real-time-audio-communication",level:4},{value:"FR-WA-07: Video Communication",id:"fr-wa-07-video-communication",level:4},{value:"3.2 Problem Service",id:"32-problem-service",level:3},{value:"FR-PS-01: Problem Provision",id:"fr-ps-01-problem-provision",level:4},{value:"FR-PS-02: Service Availability",id:"fr-ps-02-service-availability",level:4},{value:"3.3 AI Agent Service",id:"33-ai-agent-service",level:3},{value:"FR-AI-01: Solution Evaluation",id:"fr-ai-01-solution-evaluation",level:4},{value:"FR-AI-02: Model Provider Support",id:"fr-ai-02-model-provider-support",level:4},{value:"FR-AI-03: Specialized Agent Roles",id:"fr-ai-03-specialized-agent-roles",level:4},{value:"FR-AI-04: API Documentation",id:"fr-ai-04-api-documentation",level:4},{value:"FR-AI-05: Server Configuration",id:"fr-ai-05-server-configuration",level:4},{value:"4. System Interactions",id:"4-system-interactions",level:2},{value:"4.1 User Flow Sequence",id:"41-user-flow-sequence",level:3},{value:"4.2 Solution Fetching Flow",id:"42-solution-fetching-flow",level:3},{value:"4.3 Real-time Communication Flow",id:"43-real-time-communication-flow",level:3},{value:"4.4 Component Dependencies",id:"44-component-dependencies",level:3},{value:"5. External Interfaces",id:"5-external-interfaces",level:2},{value:"5.1 API Endpoints",id:"51-api-endpoints",level:3},{value:"5.1.1 AI Agent API",id:"511-ai-agent-api",level:4},{value:"5.2 User Interfaces",id:"52-user-interfaces",level:3},{value:"5.2.1 Web Application",id:"521-web-application",level:4},{value:"5.3 WebSocket Communication",id:"53-websocket-communication",level:3},{value:"5.3.1 Gemini WebSocket",id:"531-gemini-websocket",level:4},{value:"5.3.2 WebSocket Message Types",id:"532-websocket-message-types",level:4},{value:"6. Non-functional Requirements",id:"6-non-functional-requirements",level:2},{value:"6.1 Configuration Requirements",id:"61-configuration-requirements",level:3},{value:"NFR-CONF-01: API Key Management",id:"nfr-conf-01-api-key-management",level:4},{value:"NFR-CONF-02: Environment Variables",id:"nfr-conf-02-environment-variables",level:4},{value:"6.2 Security Requirements",id:"62-security-requirements",level:3},{value:"NFR-SEC-01: API Key Security",id:"nfr-sec-01-api-key-security",level:4},{value:"6.3 Performance Requirements",id:"63-performance-requirements",level:3},{value:"NFR-PERF-01: Service Availability",id:"nfr-perf-01-service-availability",level:4},{value:"7. AI Agent Details",id:"7-ai-agent-details",level:2},{value:"7.1 AI Model Integration",id:"71-ai-model-integration",level:3},{value:"7.1.1 AI Agent Service Models",id:"711-ai-agent-service-models",level:4},{value:"7.1.1.1 OpenAI Integration",id:"7111-openai-integration",level:5},{value:"7.1.1.2 Anthropic Integration",id:"7112-anthropic-integration",level:5},{value:"7.1.2 Web Application AI Integration",id:"712-web-application-ai-integration",level:4},{value:"7.1.2.1 Gemini Models",id:"7121-gemini-models",level:5},{value:"7.2 AI Agent Architecture",id:"72-ai-agent-architecture",level:3},{value:"8. Implementation Requirements",id:"8-implementation-requirements",level:2},{value:"8.1 Development Environment",id:"81-development-environment",level:3},{value:"8.1.1 Web Application",id:"811-web-application",level:4},{value:"8.1.2 AI Agent Service",id:"812-ai-agent-service",level:4},{value:"9. System Requirements",id:"9-system-requirements",level:2},{value:"9.1 Operational Requirements",id:"91-operational-requirements",level:3},{value:"10. Testing Requirements",id:"10-testing-requirements",level:2},{value:"10.1 Component Testing",id:"101-component-testing",level:3},{value:"10.1.1 Web Application Testing",id:"1011-web-application-testing",level:4},{value:"10.1.2 AI Agent Testing",id:"1012-ai-agent-testing",level:4},{value:"10.1.3 Problem Service Testing",id:"1013-problem-service-testing",level:4},{value:"11. Audio and Video Processing",id:"11-audio-and-video-processing",level:2},{value:"11.1 Audio Processing",id:"111-audio-processing",level:3},{value:"11.1.1 Audio Capture and Processing",id:"1111-audio-capture-and-processing",level:4},{value:"11.1.2 Audio Playback",id:"1112-audio-playback",level:4},{value:"11.1.3 Transcription",id:"1113-transcription",level:4},{value:"11.2 Video Processing",id:"112-video-processing",level:3},{value:"11.2.1 Camera Capture",id:"1121-camera-capture",level:4},{value:"11.2.2 Screen Sharing",id:"1122-screen-sharing",level:4},{value:"12. WebSocket Communication Protocol",id:"12-websocket-communication-protocol",level:2},{value:"12.1 Client-Server Communication",id:"121-client-server-communication",level:3},{value:"12.2 Session Management",id:"122-session-management",level:3},{value:"13. LLM Prompt Templates and Use Cases",id:"13-llm-prompt-templates-and-use-cases",level:2},{value:"13.1 Web Application Prompts (Gemini AI)",id:"131-web-application-prompts-gemini-ai",level:3},{value:"13.1.1 Initial Setup Prompt",id:"1311-initial-setup-prompt",level:4},{value:"13.1.2 Welcome Message Prompt",id:"1312-welcome-message-prompt",level:4},{value:"13.1.3 Problem Context Prompt",id:"1313-problem-context-prompt",level:4},{value:"13.1.4 Solution Context Prompt",id:"1314-solution-context-prompt",level:4},{value:"13.1.5 Transcription Prompt",id:"1315-transcription-prompt",level:4},{value:"13.2 AI Agent Prompts (OpenAI/Anthropic)",id:"132-ai-agent-prompts-openaianthropic",level:3},{value:"13.2.1 LeetCode Agent Role Prompt",id:"1321-leetcode-agent-role-prompt",level:4},{value:"13.2.2 Problem Solving Task Prompt",id:"1322-problem-solving-task-prompt",level:4},{value:"13.2.3 OpenAI Function Calling Prompt",id:"1323-openai-function-calling-prompt",level:4},{value:"13.2.4 Language-Specific Guidance Prompts",id:"1324-language-specific-guidance-prompts",level:4},{value:"14. Conclusion",id:"14-conclusion",level:2},{value:"15. Appendices",id:"15-appendices",level:2},{value:"15.1 Glossary",id:"151-glossary",level:3},{value:"15.2 References",id:"152-references",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"software-requirements-specification-srs",children:"Software Requirements Specification (SRS)"})}),"\n",(0,t.jsx)(n.h2,{id:"1-introduction",children:"1. Introduction"}),"\n",(0,t.jsx)(n.h3,{id:"11-purpose",children:"1.1 Purpose"}),"\n",(0,t.jsx)(n.p,{children:"This Software Requirements Specification (SRS) document describes the functional and non-functional requirements for the GG Interview System. The system is designed to provide an AI-powered technical interview platform with three primary components."}),"\n",(0,t.jsx)(n.h3,{id:"12-system-overview",children:"1.2 System Overview"}),"\n",(0,t.jsx)(n.p,{children:"The GG Interview System consists of three main components that work together:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"An AI agent service running on port 8000 (Python-based)"}),"\n",(0,t.jsx)(n.li,{children:"A web application interface running on port 3500 (Next.js-based)"}),"\n",(0,t.jsx)(n.li,{children:"A problem service running on port 3000"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"13-document-conventions",children:"1.3 Document Conventions"}),"\n",(0,t.jsx)(n.p,{children:"This document uses the following conventions:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Must/Shall"})," - Mandatory requirements"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Should"})," - Recommended but not mandatory"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"May/Can"})," - Optional requirements"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"14-intended-audience",children:"1.4 Intended Audience"}),"\n",(0,t.jsx)(n.p,{children:"This document is intended for developers, QA engineers, and system administrators responsible for implementing, testing, and maintaining the GG Interview System."}),"\n",(0,t.jsx)(n.h2,{id:"2-system-architecture",children:"2. System Architecture"}),"\n",(0,t.jsx)(n.h3,{id:"21-system-components",children:"2.1 System Components"}),"\n",(0,t.jsx)(n.mermaid,{value:'graph TD\n    subgraph "Frontend Layer"\n        A[Web Application<br/>localhost:3500]\n    end\n    \n    subgraph "Backend Services"\n        B[Problem Service<br/>localhost:3000]\n        C[AI Agent Service<br/>localhost:8000]\n    end\n    \n    A <--\x3e|API Calls| B\n    A <--\x3e|Solution Analysis| C\n    C <--\x3e|Problem Data| B'}),"\n",(0,t.jsx)(n.p,{children:"The GG Interview System architecture consists of three primary components:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Interview Web Application (Next.js)"}),": A user interface running on port 3500, with the main functionality accessible at ",(0,t.jsx)(n.code,{children:"/main"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Problem Service"}),": A service running on port 3000 that provides interview problems"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI Agent Service (Python)"}),": A LLM-powered service running on port 8000, implemented in the ",(0,t.jsx)(n.code,{children:"run_api.py"})," file"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"22-technology-stack",children:"2.2 Technology Stack"}),"\n",(0,t.jsx)(n.p,{children:"Based on project analysis, the technology stack includes:"}),"\n",(0,t.jsx)(n.h4,{id:"client-side",children:"Client-side"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Next.js 15.1.7"}),"\n",(0,t.jsx)(n.li,{children:"React 19.0.0"}),"\n",(0,t.jsx)(n.li,{children:"Tailwind CSS 3.4.1"}),"\n",(0,t.jsx)(n.li,{children:"Radix UI components"}),"\n",(0,t.jsx)(n.li,{children:"MermaidJS 11.6.0"}),"\n",(0,t.jsx)(n.li,{children:"GoJS 3.0.21"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"server-side",children:"Server-side"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Node.js for the Problem Service"}),"\n",(0,t.jsx)(n.li,{children:"Python for the AI Agent Service"}),"\n",(0,t.jsx)(n.li,{children:"Uvicorn for serving the AI Agent API"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"3-functional-requirements",children:"3. Functional Requirements"}),"\n",(0,t.jsx)(n.h3,{id:"31-web-application",children:"3.1 Web Application"}),"\n",(0,t.jsx)(n.h4,{id:"fr-wa-01-user-interface",children:"FR-WA-01: User Interface"}),"\n",(0,t.jsx)(n.p,{children:"The web application shall provide a user interface accessible at port 3500."}),"\n",(0,t.jsx)(n.h4,{id:"fr-wa-02-main-interview-interface",children:"FR-WA-02: Main Interview Interface"}),"\n",(0,t.jsxs)(n.p,{children:["The system shall provide the main interview functionality at the ",(0,t.jsx)(n.code,{children:"/main"})," route."]}),"\n",(0,t.jsx)(n.h4,{id:"fr-wa-03-ai-service-integration",children:"FR-WA-03: AI Service Integration"}),"\n",(0,t.jsx)(n.p,{children:"The web application shall communicate with the AI Agent Service for solution analysis."}),"\n",(0,t.jsx)(n.h4,{id:"fr-wa-04-problem-service-integration",children:"FR-WA-04: Problem Service Integration"}),"\n",(0,t.jsx)(n.p,{children:"The web application shall retrieve problems from the Problem Service."}),"\n",(0,t.jsx)(n.h4,{id:"fr-wa-05-screen-sharing",children:"FR-WA-05: Screen Sharing"}),"\n",(0,t.jsx)(n.p,{children:"The web application shall enable screen sharing capability to send visual information to Gemini AI via WebSocket."}),"\n",(0,t.jsx)(n.h4,{id:"fr-wa-06-real-time-audio-communication",children:"FR-WA-06: Real-time Audio Communication"}),"\n",(0,t.jsx)(n.p,{children:"The web application shall capture, process, and transmit audio data to Gemini AI and play audio responses in real-time."}),"\n",(0,t.jsx)(n.h4,{id:"fr-wa-07-video-communication",children:"FR-WA-07: Video Communication"}),"\n",(0,t.jsx)(n.p,{children:"The web application shall support both camera video and screen sharing modes for visual communication with Gemini AI."}),"\n",(0,t.jsx)(n.h3,{id:"32-problem-service",children:"3.2 Problem Service"}),"\n",(0,t.jsx)(n.h4,{id:"fr-ps-01-problem-provision",children:"FR-PS-01: Problem Provision"}),"\n",(0,t.jsx)(n.p,{children:"The Problem Service shall provide interview problems to the web application."}),"\n",(0,t.jsx)(n.h4,{id:"fr-ps-02-service-availability",children:"FR-PS-02: Service Availability"}),"\n",(0,t.jsx)(n.p,{children:"The Problem Service shall be accessible on port 3000."}),"\n",(0,t.jsx)(n.h3,{id:"33-ai-agent-service",children:"3.3 AI Agent Service"}),"\n",(0,t.jsx)(n.h4,{id:"fr-ai-01-solution-evaluation",children:"FR-AI-01: Solution Evaluation"}),"\n",(0,t.jsxs)(n.p,{children:["The AI Agent Service shall evaluate solutions submitted through the ",(0,t.jsx)(n.code,{children:"/api/leetcode-solutions"})," endpoint."]}),"\n",(0,t.jsx)(n.h4,{id:"fr-ai-02-model-provider-support",children:"FR-AI-02: Model Provider Support"}),"\n",(0,t.jsx)(n.p,{children:"The AI Agent Service shall support multiple AI model providers:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Claude-3-7-Sonnet from Anthropic"}),"\n",(0,t.jsx)(n.li,{children:"o3-mini-2025-01-31 from OpenAI"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"fr-ai-03-specialized-agent-roles",children:"FR-AI-03: Specialized Agent Roles"}),"\n",(0,t.jsx)(n.p,{children:'The AI Agent Service shall implement a "crew" approach with specialized agents including:'}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"LeetCode Expert"}),"\n",(0,t.jsx)(n.li,{children:"Helper Assistant"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"fr-ai-04-api-documentation",children:"FR-AI-04: API Documentation"}),"\n",(0,t.jsxs)(n.p,{children:["The AI Agent Service shall provide API documentation at the ",(0,t.jsx)(n.code,{children:"/docs"})," endpoint."]}),"\n",(0,t.jsx)(n.h4,{id:"fr-ai-05-server-configuration",children:"FR-AI-05: Server Configuration"}),"\n",(0,t.jsx)(n.p,{children:"The AI Agent Service shall run on port 8000 using Uvicorn as the ASGI server."}),"\n",(0,t.jsx)(n.h2,{id:"4-system-interactions",children:"4. System Interactions"}),"\n",(0,t.jsx)(n.h3,{id:"41-user-flow-sequence",children:"4.1 User Flow Sequence"}),"\n",(0,t.jsxs)(n.p,{children:["A detailed sequence diagram showing the complete flow of the system is available in the ",(0,t.jsx)(n.a,{href:"/gg-interview-document-website/project-docs/enhanced-sequence-diagram",children:"Enhanced System Sequence Diagrams"})," document. Below is a simplified overview:"]}),"\n",(0,t.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant User\n    participant WebApp as Web Application (Port 3500)\n    participant ProblemService as Problem Service (Port 3000)\n    participant AIAgent as AI Agent Service (Port 8000)\n    \n    User->>WebApp: Access interview platform\n    WebApp->>ProblemService: Request interview problems\n    ProblemService--\x3e>WebApp: Return problem data\n    WebApp->>User: Display problem\n    User->>WebApp: Submit solution\n    WebApp->>AIAgent: Request solution evaluation\n    AIAgent--\x3e>WebApp: Return evaluation results\n    WebApp->>User: Display feedback"}),"\n",(0,t.jsx)(n.h3,{id:"42-solution-fetching-flow",children:"4.2 Solution Fetching Flow"}),"\n",(0,t.jsx)(n.p,{children:"The solution fetching process integrates LLM processing to generate solution approaches:"}),"\n",(0,t.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant WebApp as Web Application\n    participant AIAgent as AI Agent Service\n    participant LLM as OpenAI/Anthropic LLM\n    \n    WebApp->>AIAgent: POST /api/leetcode-solutions with problem\n    AIAgent->>LLM: Send structured problem prompt\n    Note over LLM: Generate multiple solution approaches\n    LLM--\x3e>AIAgent: Return structured JSON response\n    AIAgent--\x3e>WebApp: Return formatted solutions\n    Note over WebApp: Store solutions locally for interview use"}),"\n",(0,t.jsx)(n.h3,{id:"43-real-time-communication-flow",children:"4.3 Real-time Communication Flow"}),"\n",(0,t.jsx)(n.p,{children:"The real-time interview uses WebSocket for bidirectional communication with Gemini AI:"}),"\n",(0,t.jsx)(n.mermaid,{value:"sequenceDiagram\n    actor User\n    participant WebApp as Web Application\n    participant WS as WebSocket Connection\n    participant Gemini as Gemini AI\n    \n    User->>WebApp: Start interview with media permissions\n    WebApp->>WS: Establish WebSocket connection\n    WS->>Gemini: Send initial interviewer setup prompt\n    \n    loop Real-time Communication\n        WebApp->>WS: Send screen/camera frames\n        WebApp->>WS: Send audio chunks\n        WS->>Gemini: Process visual and audio input\n        Gemini--\x3e>WS: Generate text/audio responses\n        WS--\x3e>WebApp: Return responses\n        WebApp--\x3e>User: Display text/play audio\n    end"}),"\n",(0,t.jsx)(n.h3,{id:"44-component-dependencies",children:"4.4 Component Dependencies"}),"\n",(0,t.jsx)(n.mermaid,{value:"graph TD\n    A[User] --\x3e B[Web Application<br>localhost:3500]\n    B --\x3e C[Main Interview Page<br>/main]\n    B --\x3e D[Problem Service<br>localhost:3000]\n    B --\x3e E[AI Agent Service<br>localhost:8000]\n    E --\x3e F[API Documentation<br>/docs]\n    E --\x3e G[LeetCode Solutions API<br>/api/leetcode-solutions]"}),"\n",(0,t.jsx)(n.h2,{id:"5-external-interfaces",children:"5. External Interfaces"}),"\n",(0,t.jsx)(n.h3,{id:"51-api-endpoints",children:"5.1 API Endpoints"}),"\n",(0,t.jsx)(n.h4,{id:"511-ai-agent-api",children:"5.1.1 AI Agent API"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Endpoint"}),(0,t.jsx)(n.th,{children:"Method"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/api/leetcode-solutions"})}),(0,t.jsx)(n.td,{children:"POST"}),(0,t.jsx)(n.td,{children:"Primary endpoint for the LeetCode crew API"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/docs"})}),(0,t.jsx)(n.td,{children:"GET"}),(0,t.jsx)(n.td,{children:"API documentation provided by FastAPI"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"52-user-interfaces",children:"5.2 User Interfaces"}),"\n",(0,t.jsx)(n.h4,{id:"521-web-application",children:"5.2.1 Web Application"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Interface"}),(0,t.jsx)(n.th,{children:"URL"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsx)(n.tbody,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Main Interview Page"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.a,{href:"http://localhost:3500/main",children:"http://localhost:3500/main"})}),(0,t.jsx)(n.td,{children:"Primary interface for interview functionality"})]})})]}),"\n",(0,t.jsx)(n.h3,{id:"53-websocket-communication",children:"5.3 WebSocket Communication"}),"\n",(0,t.jsx)(n.h4,{id:"531-gemini-websocket",children:"5.3.1 Gemini WebSocket"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"WebSocket Endpoint"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsx)(n.tbody,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent"})}),(0,t.jsx)(n.td,{children:"WebSocket endpoint for real-time communication with Gemini AI"})]})})]}),"\n",(0,t.jsx)(n.h4,{id:"532-websocket-message-types",children:"5.3.2 WebSocket Message Types"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Message Type"}),(0,t.jsx)(n.th,{children:"Direction"}),(0,t.jsx)(n.th,{children:"Content"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Text Messages"}),(0,t.jsx)(n.td,{children:"Client \u2192 Server"}),(0,t.jsx)(n.td,{children:"Interview questions, commands, and context"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Audio Chunks"}),(0,t.jsx)(n.td,{children:"Client \u2192 Server"}),(0,t.jsx)(n.td,{children:"Base64-encoded PCM audio data"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Image Frames"}),(0,t.jsx)(n.td,{children:"Client \u2192 Server"}),(0,t.jsx)(n.td,{children:"Base64-encoded image data"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Text Responses"}),(0,t.jsx)(n.td,{children:"Server \u2192 Client"}),(0,t.jsx)(n.td,{children:"Gemini AI text responses"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Audio Responses"}),(0,t.jsx)(n.td,{children:"Server \u2192 Client"}),(0,t.jsx)(n.td,{children:"Base64-encoded audio responses"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"6-non-functional-requirements",children:"6. Non-functional Requirements"}),"\n",(0,t.jsx)(n.h3,{id:"61-configuration-requirements",children:"6.1 Configuration Requirements"}),"\n",(0,t.jsx)(n.h4,{id:"nfr-conf-01-api-key-management",children:"NFR-CONF-01: API Key Management"}),"\n",(0,t.jsx)(n.p,{children:"The AI Agent service shall require API keys for model providers:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"OPENAI_API_KEY"})," for OpenAI model usage"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"ANTHROPIC_API_KEY"})," for Claude model usage"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"nfr-conf-02-environment-variables",children:"NFR-CONF-02: Environment Variables"}),"\n",(0,t.jsxs)(n.p,{children:["The system shall load environment variables from a ",(0,t.jsx)(n.code,{children:".env"})," file if available."]}),"\n",(0,t.jsx)(n.h3,{id:"62-security-requirements",children:"6.2 Security Requirements"}),"\n",(0,t.jsx)(n.h4,{id:"nfr-sec-01-api-key-security",children:"NFR-SEC-01: API Key Security"}),"\n",(0,t.jsx)(n.p,{children:"API keys shall be securely stored in environment variables and not hardcoded in the codebase."}),"\n",(0,t.jsx)(n.h3,{id:"63-performance-requirements",children:"6.3 Performance Requirements"}),"\n",(0,t.jsx)(n.h4,{id:"nfr-perf-01-service-availability",children:"NFR-PERF-01: Service Availability"}),"\n",(0,t.jsx)(n.p,{children:"All services shall be available on their respective ports:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Web Application: Port 3500"}),"\n",(0,t.jsx)(n.li,{children:"Problem Service: Port 3000"}),"\n",(0,t.jsx)(n.li,{children:"AI Agent Service: Port 8000"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"7-ai-agent-details",children:"7. AI Agent Details"}),"\n",(0,t.jsx)(n.h3,{id:"71-ai-model-integration",children:"7.1 AI Model Integration"}),"\n",(0,t.jsx)(n.h4,{id:"711-ai-agent-service-models",children:"7.1.1 AI Agent Service Models"}),"\n",(0,t.jsx)(n.p,{children:"The AI Agent supports two model providers that can be configured via environment variables:"}),"\n",(0,t.jsx)(n.h5,{id:"7111-openai-integration",children:"7.1.1.1 OpenAI Integration"}),"\n",(0,t.jsx)(n.p,{children:"When configured to use OpenAI, the system shall:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use the o3-mini-2025-01-31 model"}),"\n",(0,t.jsx)(n.li,{children:"Require a valid OPENAI_API_KEY in environment variables"}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"7112-anthropic-integration",children:"7.1.1.2 Anthropic Integration"}),"\n",(0,t.jsx)(n.p,{children:"When configured to use Anthropic, the system shall:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use the Claude-3-7-Sonnet model"}),"\n",(0,t.jsx)(n.li,{children:"Require a valid ANTHROPIC_API_KEY in environment variables"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"712-web-application-ai-integration",children:"7.1.2 Web Application AI Integration"}),"\n",(0,t.jsx)(n.h5,{id:"7121-gemini-models",children:"7.1.2.1 Gemini Models"}),"\n",(0,t.jsx)(n.p,{children:"The web application integrates with Google's Gemini AI via WebSocket:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Uses ",(0,t.jsx)(n.code,{children:"models/gemini-2.0-flash-exp"})," for real-time interview communication"]}),"\n",(0,t.jsxs)(n.li,{children:["Uses ",(0,t.jsx)(n.code,{children:"gemini-1.5-pro"})," for audio transcription"]}),"\n",(0,t.jsxs)(n.li,{children:["Uses ",(0,t.jsx)(n.code,{children:"gemini-1.5-flash-8b"})," for additional text processing"]}),"\n",(0,t.jsx)(n.li,{children:"Requires NEXT_PUBLIC_GEMINI_API_KEY environment variable"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"72-ai-agent-architecture",children:"7.2 AI Agent Architecture"}),"\n",(0,t.jsx)(n.mermaid,{value:"graph TB\n    A[run_api.py] --\x3e B[uvicorn Server]\n    B --\x3e C[src.crew_api:app]\n    C --\x3e D[LeetCode Expert Agent]\n    C --\x3e E[Helper Assistant Agent]\n    D --\x3e F[AI Model Provider]\n    E --\x3e F\n    F --\x3e G[OpenAI Model]\n    F --\x3e H[Claude Model]"}),"\n",(0,t.jsx)(n.h2,{id:"8-implementation-requirements",children:"8. Implementation Requirements"}),"\n",(0,t.jsx)(n.h3,{id:"81-development-environment",children:"8.1 Development Environment"}),"\n",(0,t.jsx)(n.h4,{id:"811-web-application",children:"8.1.1 Web Application"}),"\n",(0,t.jsx)(n.p,{children:"From the package.json, the following development environment configurations are required:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'"scripts": {\n  "dev": "rm -rf .next && NEXT_SKIP_APP_BUNDLE=true next dev --turbopack -p 3500",\n  "build": "rm -rf .next && NEXT_SKIP_APP_BUNDLE=true next build",\n  "start": "next start -p 3500",\n  "lint": "next lint",\n  "clear-cache": "rm -rf .next"\n}\n'})}),"\n",(0,t.jsx)(n.h4,{id:"812-ai-agent-service",children:"8.1.2 AI Agent Service"}),"\n",(0,t.jsx)(n.p,{children:"From run_api.py, the service is started using:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'uvicorn.run(\n    "src.crew_api:app",\n    host=args.host,\n    port=args.port,\n    reload=args.reload\n)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"9-system-requirements",children:"9. System Requirements"}),"\n",(0,t.jsx)(n.h3,{id:"91-operational-requirements",children:"9.1 Operational Requirements"}),"\n",(0,t.jsx)(n.mermaid,{value:"graph TD\n    A[GG Interview System] --\x3e B[Node.js Environment]  \n    A --\x3e C[Python Environment]\n    B --\x3e D[Port 3000 Available]\n    B --\x3e E[Port 3500 Available]\n    C --\x3e F[Port 8000 Available]\n    C --\x3e G[AI Provider API Keys]\n    G --\x3e H[OpenAI API Key]\n    G --\x3e I[Anthropic API Key]\n    G --\x3e J[Gemini API Key]\n    B --\x3e K[Browser API Support]\n    K --\x3e L[WebSocket API]\n    K --\x3e M[MediaDevices API]\n    K --\x3e N[Web Audio API]\n    K --\x3e O[Screen Capture API]"}),"\n",(0,t.jsx)(n.p,{children:"The system requires:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Available ports: 3000, 3500, and 8000"}),"\n",(0,t.jsx)(n.li,{children:"Appropriate environment setup for Node.js and Python"}),"\n",(0,t.jsx)(n.li,{children:"Valid API keys for OpenAI, Anthropic, and/or Gemini"}),"\n",(0,t.jsxs)(n.li,{children:["Modern browser with support for:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"WebSocket API for real-time communication"}),"\n",(0,t.jsx)(n.li,{children:"MediaDevices API for camera and microphone access"}),"\n",(0,t.jsx)(n.li,{children:"Web Audio API for audio processing"}),"\n",(0,t.jsx)(n.li,{children:"Screen Capture API for screen sharing"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"10-testing-requirements",children:"10. Testing Requirements"}),"\n",(0,t.jsx)(n.h3,{id:"101-component-testing",children:"10.1 Component Testing"}),"\n",(0,t.jsx)(n.h4,{id:"1011-web-application-testing",children:"10.1.1 Web Application Testing"}),"\n",(0,t.jsx)(n.p,{children:"The web application shall be tested for:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"UI rendering"}),"\n",(0,t.jsx)(n.li,{children:"API integration with Problem Service"}),"\n",(0,t.jsx)(n.li,{children:"API integration with AI Agent Service"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"1012-ai-agent-testing",children:"10.1.2 AI Agent Testing"}),"\n",(0,t.jsx)(n.p,{children:"The AI Agent shall be tested for:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"API functionality"}),"\n",(0,t.jsx)(n.li,{children:"Model provider integration"}),"\n",(0,t.jsx)(n.li,{children:"Response quality"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"1013-problem-service-testing",children:"10.1.3 Problem Service Testing"}),"\n",(0,t.jsx)(n.p,{children:"The Problem Service shall be tested for:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Problem retrieval"}),"\n",(0,t.jsx)(n.li,{children:"API functionality"}),"\n",(0,t.jsx)(n.li,{children:"Integration with Web Application"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"11-audio-and-video-processing",children:"11. Audio and Video Processing"}),"\n",(0,t.jsx)(n.h3,{id:"111-audio-processing",children:"11.1 Audio Processing"}),"\n",(0,t.jsx)(n.h4,{id:"1111-audio-capture-and-processing",children:"11.1.1 Audio Capture and Processing"}),"\n",(0,t.jsx)(n.p,{children:"The system shall capture and process audio using the following techniques:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use Web Audio API's AudioContext and AudioWorkletNode"}),"\n",(0,t.jsx)(n.li,{children:"Process audio at 24,000 Hz sample rate"}),"\n",(0,t.jsx)(n.li,{children:"Convert PCM audio data to WAV format for transmission"}),"\n",(0,t.jsx)(n.li,{children:"Transmit audio chunks in real-time via WebSocket"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"1112-audio-playback",children:"11.1.2 Audio Playback"}),"\n",(0,t.jsx)(n.p,{children:"The system shall handle AI-generated audio responses:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Decode Base64-encoded audio responses"}),"\n",(0,t.jsx)(n.li,{children:"Create AudioBufferSourceNode for playback"}),"\n",(0,t.jsx)(n.li,{children:"Queue audio segments for continuous playback"}),"\n",(0,t.jsx)(n.li,{children:"Provide audio level visualization"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"1113-transcription",children:"11.1.3 Transcription"}),"\n",(0,t.jsx)(n.p,{children:"The system shall transcribe user audio:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use Gemini AI for speech-to-text processing"}),"\n",(0,t.jsx)(n.li,{children:"Rate-limit transcription requests (max 1 per 2 seconds)"}),"\n",(0,t.jsx)(n.li,{children:"Skip audio chunks shorter than minimum threshold"}),"\n",(0,t.jsx)(n.li,{children:"Pause transcription during critical operations"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"112-video-processing",children:"11.2 Video Processing"}),"\n",(0,t.jsx)(n.h4,{id:"1121-camera-capture",children:"11.2.1 Camera Capture"}),"\n",(0,t.jsx)(n.p,{children:"The system shall support camera video capture:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use MediaDevices API to access user camera"}),"\n",(0,t.jsx)(n.li,{children:"Render video stream to HTML video element"}),"\n",(0,t.jsx)(n.li,{children:"Capture frames at regular intervals (1 per second)"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"1122-screen-sharing",children:"11.2.2 Screen Sharing"}),"\n",(0,t.jsx)(n.p,{children:"The system shall support screen sharing:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use getDisplayMedia() API to capture screen"}),"\n",(0,t.jsx)(n.li,{children:"Allow user to select which screen/window to share"}),"\n",(0,t.jsx)(n.li,{children:"Send screen captures to Gemini AI via WebSocket"}),"\n",(0,t.jsx)(n.li,{children:"Handle screen sharing session termination"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"12-websocket-communication-protocol",children:"12. WebSocket Communication Protocol"}),"\n",(0,t.jsx)(n.h3,{id:"121-client-server-communication",children:"12.1 Client-Server Communication"}),"\n",(0,t.jsx)(n.p,{children:"The system implements a bidirectional communication protocol with Gemini AI:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Establish secure WebSocket connection"}),"\n",(0,t.jsx)(n.li,{children:"Send initial setup messages with interview context"}),"\n",(0,t.jsx)(n.li,{children:"Stream audio, video, and text data in real-time"}),"\n",(0,t.jsx)(n.li,{children:"Receive and process AI responses"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"122-session-management",children:"12.2 Session Management"}),"\n",(0,t.jsx)(n.p,{children:"The system manages WebSocket sessions:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Generate unique identifiers for each session"}),"\n",(0,t.jsx)(n.li,{children:"Handle connection errors and reconnection"}),"\n",(0,t.jsx)(n.li,{children:"Implement graceful disconnection"}),"\n",(0,t.jsx)(n.li,{children:"Manage state transitions between problems"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"13-llm-prompt-templates-and-use-cases",children:"13. LLM Prompt Templates and Use Cases"}),"\n",(0,t.jsx)(n.h3,{id:"131-web-application-prompts-gemini-ai",children:"13.1 Web Application Prompts (Gemini AI)"}),"\n",(0,t.jsx)(n.h4,{id:"1311-initial-setup-prompt",children:"13.1.1 Initial Setup Prompt"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"You are an **expert coding interviewer** conducting a live coding session. \nPlease greet the candidate warmly as soon as possible, and don't wait for them to speak first.\n\nYou are an **expert coding interviewer** conducting a live coding session. \nInitially, you don't know which problem the candidate will work on, so don't assume any specific problem. \nYou can see the candidate's screen as they code, and your primary role is to provide guidance and encouragement. \nYour approach should be supportive and educational, helping them understand the requirements better. \nRegularly ask them about their thought process with questions like 'Why did you choose this approach?' \nor 'Have you considered these edge cases?' to deepen their understanding. \nWhen you see them implementing a solution, inquire about their reasoning to help them articulate their thoughts. \nBe supportive, offer timely hints, and create a positive learning environment. \nIf a new problem is selected, completely forget any previous problems and focus only on the current one.\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use Case"}),": This prompt is sent during the initial WebSocket connection setup in ",(0,t.jsx)(n.code,{children:"sendInitialSetup()"})," method of the ",(0,t.jsx)(n.code,{children:"GeminiWebSocket"})," class. It establishes the role of Gemini AI as a coding interviewer and sets the general behavior guidelines."]}),"\n",(0,t.jsx)(n.h4,{id:"1312-welcome-message-prompt",children:"13.1.2 Welcome Message Prompt"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Please greet the candidate warmly as soon as possible, and don't wait for them to speak first.\nYou should ask them to open their code editor, and until you see their code editor open, you should say let get started.\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use Case"}),": Sent immediately after the initial setup to prompt Gemini to greet the user and initiate the interview session."]}),"\n",(0,t.jsx)(n.h4,{id:"1313-problem-context-prompt",children:"13.1.3 Problem Context Prompt"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"IMPORTANT: Forget any previous problems. A new problem has been selected:\n\n**Title**: [Problem Title]\n\n**Problem Description**:\n[Problem Description]\n\nAs an expert interviewer:\n1. Actively guide the candidate with encouragement and support.\n2. Ask questions about their approach to help them understand the requirements better.\n3. Inquire about why they chose specific implementations to deepen their understanding.\n4. Help them identify edge cases and potential optimizations.\n5. Monitor their code as they work, offering timely and constructive guidance.\n\nYour goal is to create a supportive environment while helping them improve their problem-solving skills.\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use Case"}),": This prompt is sent in the ",(0,t.jsx)(n.code,{children:"sendNewProblemContext()"})," method when a new problem is selected. It provides Gemini with the problem title and description and reinforces the interviewer role guidelines."]}),"\n",(0,t.jsx)(n.h4,{id:"1314-solution-context-prompt",children:"13.1.4 Solution Context Prompt"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'Solutions loaded for "[Problem Title]" ([Number] solutions). Don\'t mention or discuss solutions unless candidate explicitly asks for a hint.\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use Case"}),": Sent in the ",(0,t.jsx)(n.code,{children:"sendSolutionContext()"})," method when solutions are loaded for a problem. This instructs Gemini to be aware of solutions but not to mention them unless explicitly asked for hints."]}),"\n",(0,t.jsx)(n.h4,{id:"1315-transcription-prompt",children:"13.1.5 Transcription Prompt"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Transcribe this audio:\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use Case"}),": Used in the ",(0,t.jsx)(n.code,{children:"transcribeAudio()"})," method of the ",(0,t.jsx)(n.code,{children:"TranscriptionService"})," class when sending audio data to Gemini for transcription."]}),"\n",(0,t.jsx)(n.h3,{id:"132-ai-agent-prompts-openaianthropic",children:"13.2 AI Agent Prompts (OpenAI/Anthropic)"}),"\n",(0,t.jsx)(n.h4,{id:"1321-leetcode-agent-role-prompt",children:"13.2.1 LeetCode Agent Role Prompt"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"You are an expert in algorithms and data structures with years of experience solving complex programming problems. You specialize in analyzing problems thoroughly, identifying optimal approaches, and implementing clean, efficient solutions with proper explanations of your thought process and complexity analysis.\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use Case"}),": Used in the ",(0,t.jsx)(n.code,{children:"_create_agent()"})," method of the ",(0,t.jsx)(n.code,{children:"LeetCodeAgent"})," class to define the agent's role and expertise."]}),"\n",(0,t.jsx)(n.h4,{id:"1322-problem-solving-task-prompt",children:"13.2.2 Problem Solving Task Prompt"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Solve the following LeetCode problem using [language]:\n\n[problem_description]\n\nProvide multiple solution approaches with detailed explanations, code implementation, and complexity analysis.\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use Case"}),": Used in the ",(0,t.jsx)(n.code,{children:"create_leetcode_task()"})," method of the ",(0,t.jsx)(n.code,{children:"AgentCrew"})," class to create a task for solving LeetCode problems."]}),"\n",(0,t.jsx)(n.h4,{id:"1323-openai-function-calling-prompt",children:"13.2.3 OpenAI Function Calling Prompt"}),"\n",(0,t.jsx)(n.p,{children:"The AI agent uses a structured output format defined by the following Pydantic models:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class Approach:\n    """A single approach to solving a LeetCode problem"""\n    rank: int  # Rank/order of the approach (1 is best)\n    title: str  # Title of the approach\n    description: str  # Detailed explanation of the approach\n    time_complexity: str  # Time complexity analysis\n    space_complexity: str  # Space complexity analysis\n    code: str  # Code implementation of the approach\n    edge_cases: str  # Discussion of edge cases\n    test_examples: str  # Example test cases\n\nclass LeetCodeSolution:\n    """Complete solution to a LeetCode problem with multiple approaches"""\n    introduction: str  # Overview of the problem and approaches\n    approaches: List[Approach]  # List of solution approaches\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use Case"}),": Used in the ",(0,t.jsx)(n.code,{children:"solve_problem()"})," method of the ",(0,t.jsx)(n.code,{children:"LeetCodeAgent"})," class to generate structured solution responses via OpenAI function calling."]}),"\n",(0,t.jsx)(n.h4,{id:"1324-language-specific-guidance-prompts",children:"13.2.4 Language-Specific Guidance Prompts"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Python:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Use Python's built-in functions and standard libraries where appropriate. Aim for Pythonic code that is both efficient and readable.\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Java:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Follow Java conventions and utilize appropriate data structures from Java Collections Framework. Consider both readability and performance.\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Use Case"}),": Added to the system message in the ",(0,t.jsx)(n.code,{children:"solve_problem()"})," method of the ",(0,t.jsx)(n.code,{children:"LeetCodeAgent"})," class based on the selected programming language."]}),"\n",(0,t.jsx)(n.h2,{id:"14-conclusion",children:"14. Conclusion"}),"\n",(0,t.jsx)(n.p,{children:"This Software Requirements Specification document outlines the requirements for the GG Interview System based on the observed project structure and code. The system consists of three main services that work together to provide an interview platform:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Web Application"}),": A Next.js-based interface running on port 3500 that implements real-time screen sharing, audio/video communication with Gemini AI via WebSocket"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Problem Service"}),": A service running on port 3000 that provides interview problems"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI Agent Service"}),": A Python-based service running on port 8000 that evaluates solutions using AI models"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The system supports integration with OpenAI, Anthropic, and Google Gemini AI models, configured through environment variables."}),"\n",(0,t.jsx)(n.h2,{id:"15-appendices",children:"15. Appendices"}),"\n",(0,t.jsx)(n.h3,{id:"151-glossary",children:"15.1 Glossary"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Term"}),(0,t.jsx)(n.th,{children:"Definition"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"AI Agent"}),(0,t.jsx)(n.td,{children:"The Python-based service that evaluates code submissions using AI models"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Problem Service"}),(0,t.jsx)(n.td,{children:"The service running on port 3000 that provides interview problems"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Web Application"}),(0,t.jsx)(n.td,{children:"The Next.js application running on port 3500 that serves as the user interface"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"LeetCode Crew"}),(0,t.jsx)(n.td,{children:"The specialized AI agents working together to analyze solutions"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"WebSocket"}),(0,t.jsx)(n.td,{children:"Bidirectional communication protocol for real-time data exchange"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Screen Sharing"}),(0,t.jsx)(n.td,{children:"Feature allowing users to share their screen content with Gemini AI"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"PCM"}),(0,t.jsx)(n.td,{children:"Pulse-Code Modulation, a method used to digitally represent sampled analog signals"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"AudioWorklet"}),(0,t.jsx)(n.td,{children:"Web Audio API interface for audio processing"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"MediaDevices"}),(0,t.jsx)(n.td,{children:"Web API providing access to connected media input devices"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"152-references",children:"15.2 References"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Web Application package.json - Dependencies and scripts configuration"}),"\n",(0,t.jsx)(n.li,{children:"AI Agent run_api.py - Server configuration and initialization"}),"\n",(0,t.jsx)(n.li,{children:"Project Directory Structure - Component organization and relationships"}),"\n",(0,t.jsx)(n.li,{children:"geminiWebSocket.ts - WebSocket implementation for Gemini communication"}),"\n",(0,t.jsx)(n.li,{children:"CameraPreview.tsx - Screen sharing and audio/video capture implementation"}),"\n",(0,t.jsx)(n.li,{children:"transcriptionService.ts - Audio transcription service implementation"}),"\n",(0,t.jsx)(n.li,{children:"audioUtils.ts - Audio processing utilities"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);